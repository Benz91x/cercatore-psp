# Nome del nostro flusso di lavoro (workflow)
name: Cerca Annunci Subito

# Eventi che attivano il workflow
on:
  # Permette di avviarlo manualmente dalla pagina Actions di GitHub
  workflow_dispatch:
  
  # Lo avvia automaticamente ogni ora, tutti i giorni
  schedule:
    - cron: '0 * * * *'

# Lavori (jobs) da eseguire
jobs:
  # Nome del nostro unico lavoro
  build:
    # Tipo di macchina virtuale su cui eseguire il lavoro
    runs-on: ubuntu-latest

    # Passaggi (steps) da eseguire in sequenza
    steps:
      # 1. Fa il "checkout" del codice dal nostro repository sulla macchina virtuale
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2. Imposta l'ambiente Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10' # Usiamo una versione stabile di Python

      # 3. Installa le dipendenze necessarie per lo script
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager-chrome beautifulsoup4 requests

      # 4. Esegue il nostro script Python
      - name: Run scraper script
        # Passa i segreti che abbiamo impostato come variabili d'ambiente allo script
        env:
          TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python bot_automatico.py

      # 5. (Opzionale ma consigliato) Salva il file di report aggiornato nel repository
      # Questo passaggio permette di mantenere la cronologia degli annunci tra un'esecuzione e l'altra
      - name: Commit and push if changed
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add report_annunci_psp.txt
          # Esegue il commit solo se il file Ã¨ cambiato
          git diff --staged --quiet || git commit -m "Aggiorna cronologia annunci"
          git push
